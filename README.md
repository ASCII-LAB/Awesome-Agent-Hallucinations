# Awesome-Agent-Hallucinations
Welcome to the **Awesome-Agent-Hallucinations** repository! This repository is a library of works related to **Large Language Models (LLMs) based Agent Hallucinations**. For a detailed introduction, please refer our survey paper:

:sparkles:**LLM-based Agents Suffer from Hallucinations: A Survey of Taxonomy, Methods, and Directions**:sparkles:

<p>
  <img src="imgs/agent_intro.png" width="95%" />
</p>
:star_struck:An overview of agent goal completion. 

* Within the loop, the LLM-based agent carries out external behaviors including reasoning, execution, perception, and memorization, guided by its internal belief state.
* Throughout this process, the environment dynamically evolves in response to the agent’s decisions, while task allocation within the LLM-based multi-agent system further enhances the fulfillment of user requirements.


## :star2:1 Reasoning Hallucinations
* **LLM+Map: Bimanual Robot Task Planning Using Large Language Models And Planning Domain Definition Language** [![arXiv](https://img.shields.io/badge/arXiv-2025.03-limegreen)](https://arxiv.org/abs/2503.17309) [![Code](https://img.shields.io/badge/Code-GitHub-cornflowerblue)](https://github.com/Kchu/LLM-MAP)
* **Large language models for planning: A comprehensive and systematic survey** [![arXiv](https://img.shields.io/badge/arXiv-2025.05-limegreen)](https://arxiv.org/abs/2505.19683)
* **Plan-then-execute: An empirical study of user trust and team performance when using llm agents as a daily assistant** [![CHI](https://img.shields.io/badge/CHI-2025-limegreen)](https://dl.acm.org/doi/full/10.1145/3706598.3713218)
* **Igniting Language Intelligence: The Hitchhiker's Guide From Chain-of-Thought Reasoning to Language Agents** [![CSUR](https://img.shields.io/badge/CSUR-2025-limegreen)](https://dl.acm.org/doi/full/10.1145/3719341) [![Code](https://img.shields.io/badge/Code-GitHub-cornflowerblue)](https://github.com/Zoeyyao27/CoT-Igniting-Agent)
* **Divide and conquer in multi-agent planning** [![AAAI](https://img.shields.io/badge/AAAI-1994-limegreen)](https://dl.acm.org/doi/10.5555/2891730.2891788)
* **Hm-rag: Hierarchical multi-agent multimodal retrieval augmented generation** [![arxiv](https://img.shields.io/badge/arxiv-2025.04-limegreen)](https://arxiv.org/abs/2504.12330) [![Code](https://img.shields.io/badge/Code-GitHub-cornflowerblue)](https://github.com/ocean-luna/HMRAG)
* **AI Agents vs. Agentic AI: A Conceptual Taxonomy, Applications and Challenge** [![arxiv](https://img.shields.io/badge/arxiv-2025.05-limegreen)](https://arxiv.org/abs/2505.10468)
* **REMAC: Self-Reflective and Self-Evolving Multi-Agent Collaboration for Long-Horizon Robot Manipulation** [![arxiv](https://img.shields.io/badge/arxiv-2025.03-limegreen)](https://arxiv.org/abs/2503.22122) [![Code](https://img.shields.io/badge/Code-GitHub-cornflowerblue)](https://github.com/reamac-repo/remac-repo)
* **MetaMind: Modeling Human Social Thoughts with Metacognitive Multi-Agent Systems** [![arxiv](https://img.shields.io/badge/arxiv-2025.05-limegreen)](https://arxiv.org/abs/2505.18943) [![Code](https://img.shields.io/badge/Code-GitHub-cornflowerblue)](https://github.com/XMZhangAI/MetaMind)
* **Beyond Bare Queries: Open-Vocabulary Object Grounding with 3D Scene Graph** [![ICRA](https://img.shields.io/badge/ICRA-2025-limegreen)](https://arxiv.org/abs/2406.07113) [![Code](https://img.shields.io/badge/Code-GitHub-cornflowerblue)](https://github.com/linukc/BeyondBareQueries)
* **Modeling Future Conversation Turns to Teach LLMs to Ask Clarifying Questions** [![ICLR](https://img.shields.io/badge/ICLR-2025-limegreen)](https://arxiv.org/abs/2410.13788)
* **Why Does ChatGPT Fall Short in Providing Truthful Answers?** [![ICBINB](https://img.shields.io/badge/NeurIPS_workshop_ICBINB-2023-limegreen)](https://arxiv.org/abs/2304.10513)
* **Do LLMs Understand Ambiguity in Text? A Case Study in Open-world Question Answering** [![IEEE BigData](https://img.shields.io/badge/IEEE_BigData-2024-limegreen)](https://arxiv.org/abs/2411.12395)
* **We‘re Afraid Language Models Aren‘t Modeling Ambiguity** [![EMNLP](https://img.shields.io/badge/EMNLP-2023-limegreen)](https://arxiv.org/abs/2304.14399) [![Code](https://img.shields.io/badge/Code-GitHub-cornflowerblue)](https://github.com/alisawuffles/ambient)
* **Learning to Clarify: Multi-turn Conversations with Action-Based Contrastive Self-Training** [![ICLR](https://img.shields.io/badge/ICLR-2025-limegreen)](https://arxiv.org/abs/2406.00222) [![Code](https://img.shields.io/badge/Code-GitHub-cornflowerblue)](https://github.com/google-research/google-research/tree/master/learning_to_clarify)
* **Goal Awareness for Conversational AI: Proactivity, Non-collaborativity, and Beyond** [![ACL](https://img.shields.io/badge/ACL-2023-limegreen)](https://openreview.net/forum?id=O2hA1ORrdM)
* **Active Task Disambiguation with LLMs** [![ICLR](https://img.shields.io/badge/ICLR-2025-limegreen)](https://openreview.net/forum?id=JAMxRSXLFz)
* **Conversational health agents: A personalized llm-powered agent framework** [![JAMIA](https://img.shields.io/badge/JAMIA-2025-limegreen)](https://arxiv.org/abs/2310.02374) [![Code](https://img.shields.io/badge/Code-GitHub-cornflowerblue)](https://github.com/Institute4FutureHealth/CHA)
* **Opera: Alleviating hallucination in multi-modal large language models via over-trust penalty and retrospection-allocation** [![CVPR](https://img.shields.io/badge/CVPR-2024-limegreen)](https://arxiv.org/abs/2311.17911) [![Code](https://img.shields.io/badge/Code-GitHub-cornflowerblue)](https://github.com/shikiw/OPERA)



## :star2:2 Execution Hallucinations


* **Toolace: Winning the points of llm function calling** [![arxiv](https://img.shields.io/badge/arxiv-2024.09-limegreen)](https://arxiv.org/abs/2409.00920) [![models](https://img.shields.io/badge/Models-huggingface-9F88FF)](https://huggingface.co/Team-ACE) [![datasets](https://img.shields.io/badge/Datasets-huggingface-00DDAA)](https://huggingface.co/Team-ACE)
* **Autonomous Agents for Collaborative Task under Information Asymmetry** [![NeurIPS](https://img.shields.io/badge/NeurlPS-2024-limegreen)](https://openreview.net/forum?id=mp6OWpDIJC) [![Code](https://img.shields.io/badge/Code-GitHub-cornflowerblue)](https://github.com/thinkwee/iAgents)
* **Knowledge unlearning for llms: Tasks, methods, and challenges** [![CoRR](https://img.shields.io/badge/CoRR-2023-limegreen)](https://openreview.net/forum?id=PvwM8Ehrmm)
* **ALGO: Synthesizing Algorithmic Programs with Generated Oracle Verifiers** [![NeurIPS](https://img.shields.io/badge/NeurlPS-2023-limegreen)](https://arxiv.org/abs/2305.14591) [![Code](https://img.shields.io/badge/Code-GitHub-cornflowerblue)](https://github.com/zkx06111/ALGO)

## :star2:3 Perception Hallucinations



## :star2:4 Memorization Hallucinations




## :star2:5 Communication Hallucinations


