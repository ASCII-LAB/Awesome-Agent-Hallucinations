# Awesome-Agent-Hallucinations
Welcome to the **Awesome-Agent-Hallucinations** repository! This repository is a library of works related to **Large Language Models (LLMs) based Agent Hallucinations**. For a detailed introduction, please refer our survey paper:

:sparkles:**LLM-based Agents Suffer from Hallucinations: A Survey of Taxonomy, Methods, and Directions**:sparkles:

<p>
  <img src="imgs/agent_intro.png" width="95%" />
</p>
:star_struck:An overview of agent goal completion. 

* Within the loop, the LLM-based agent carries out external behaviors including reasoning, execution, perception, and memorization, guided by its internal belief state.
* Throughout this process, the environment dynamically evolves in response to the agent’s decisions, while task allocation within the LLM-based multi-agent system further enhances the fulfillment of user requirements.


## :star2:1 Reasoning Hallucinations
* **LLM+Map: Bimanual Robot Task Planning Using Large Language Models And Planning Domain Definition Language** [![arXiv](https://img.shields.io/badge/arXiv-2025.03-limegreen)](https://arxiv.org/abs/2503.17309) [![Code](https://img.shields.io/badge/Code-GitHub-cornflowerblue)](https://github.com/Kchu/LLM-MAP)
* **Large language models for planning: A comprehensive and systematic survey** [![arXiv](https://img.shields.io/badge/arXiv-2025.05-limegreen)](https://arxiv.org/abs/2505.19683)
* **Plan-then-execute: An empirical study of user trust and team performance when using llm agents as a daily assistant** [![CHI](https://img.shields.io/badge/CHI-2025-limegreen)](https://dl.acm.org/doi/full/10.1145/3706598.3713218)
* **Igniting Language Intelligence: The Hitchhiker's Guide From Chain-of-Thought Reasoning to Language Agents** [![CSUR](https://img.shields.io/badge/CSUR-2025-limegreen)](https://dl.acm.org/doi/full/10.1145/3719341) [![Code](https://img.shields.io/badge/Code-GitHub-cornflowerblue)](https://github.com/Zoeyyao27/CoT-Igniting-Agent)
* **Divide and conquer in multi-agent planning** [![AAAI](https://img.shields.io/badge/AAAI-1994-limegreen)](https://dl.acm.org/doi/10.5555/2891730.2891788)
* **Hm-rag: Hierarchical multi-agent multimodal retrieval augmented generation** [![arxiv](https://img.shields.io/badge/arxiv-2025.04-limegreen)](https://arxiv.org/abs/2504.12330) [![Code](https://img.shields.io/badge/Code-GitHub-cornflowerblue)](https://github.com/ocean-luna/HMRAG)
* **AI Agents vs. Agentic AI: A Conceptual Taxonomy, Applications and Challenge** [![arxiv](https://img.shields.io/badge/arxiv-2025.05-limegreen)](https://arxiv.org/abs/2505.10468)
* **REMAC: Self-Reflective and Self-Evolving Multi-Agent Collaboration for Long-Horizon Robot Manipulation** [![arxiv](https://img.shields.io/badge/arxiv-2025.03-limegreen)](https://arxiv.org/abs/2503.22122) [![Code](https://img.shields.io/badge/Code-GitHub-cornflowerblue)](https://github.com/reamac-repo/remac-repo)
* **MetaMind: Modeling Human Social Thoughts with Metacognitive Multi-Agent Systems** [![arxiv](https://img.shields.io/badge/arxiv-2025.05-limegreen)](https://arxiv.org/abs/2505.18943) [![Code](https://img.shields.io/badge/Code-GitHub-cornflowerblue)](https://github.com/XMZhangAI/MetaMind)
* **Beyond Bare Queries: Open-Vocabulary Object Grounding with 3D Scene Graph** [![ICRA](https://img.shields.io/badge/ICRA-2025-limegreen)](https://arxiv.org/abs/2406.07113) [![Code](https://img.shields.io/badge/Code-GitHub-cornflowerblue)](https://github.com/linukc/BeyondBareQueries)
* **Modeling Future Conversation Turns to Teach LLMs to Ask Clarifying Questions** [![ICLR](https://img.shields.io/badge/ICLR-2025-limegreen)](https://arxiv.org/abs/2410.13788)
* **Why Does ChatGPT Fall Short in Providing Truthful Answers?** [![ICBINB](https://img.shields.io/badge/NeurIPS_workshop_ICBINB-2023-limegreen)](https://arxiv.org/abs/2304.10513)
* **Do LLMs Understand Ambiguity in Text? A Case Study in Open-world Question Answering** [![IEEE BigData](https://img.shields.io/badge/IEEE_BigData-2024-limegreen)](https://arxiv.org/abs/2411.12395)
* **We‘re Afraid Language Models Aren‘t Modeling Ambiguity** [![EMNLP](https://img.shields.io/badge/EMNLP-2023-limegreen)](https://arxiv.org/abs/2304.14399) [![Code](https://img.shields.io/badge/Code-GitHub-cornflowerblue)](https://github.com/alisawuffles/ambient)
* **Learning to Clarify: Multi-turn Conversations with Action-Based Contrastive Self-Training** [![ICLR](https://img.shields.io/badge/ICLR-2025-limegreen)](https://arxiv.org/abs/2406.00222) [![Code](https://img.shields.io/badge/Code-GitHub-cornflowerblue)](https://github.com/google-research/google-research/tree/master/learning_to_clarify)
* **Goal Awareness for Conversational AI: Proactivity, Non-collaborativity, and Beyond** [![ACL](https://img.shields.io/badge/ACL-2023-limegreen)](https://openreview.net/forum?id=O2hA1ORrdM)
* **Active Task Disambiguation with LLMs** [![ICLR](https://img.shields.io/badge/ICLR-2025-limegreen)](https://openreview.net/forum?id=JAMxRSXLFz)
* **Conversational health agents: A personalized llm-powered agent framework** [![JAMIA](https://img.shields.io/badge/JAMIA-2025-limegreen)](https://arxiv.org/abs/2310.02374) [![Code](https://img.shields.io/badge/Code-GitHub-cornflowerblue)](https://github.com/Institute4FutureHealth/CHA)
* **Opera: Alleviating hallucination in multi-modal large language models via over-trust penalty and retrospection-allocation** [![CVPR](https://img.shields.io/badge/CVPR-2024-limegreen)](https://arxiv.org/abs/2311.17911) [![Code](https://img.shields.io/badge/Code-GitHub-cornflowerblue)](https://github.com/shikiw/OPERA)
* **Navigating the overkill in large language models** [![ACL](https://img.shields.io/badge/ACL-2024-limegreen)](https://aclanthology.org/2024.acl-long.253/)
* **Mitigating Hallucinations in Multimodal Spatial Relations through Constraint-Aware Prompting** [![NAACL](https://img.shields.io/badge/NAACL-2025-limegreen)](https://arxiv.org/abs/2502.08317v1)
* **AriGraph: Learning Knowledge Graph World Models with Episodic Memory for LLM Agents** [![IJCAI](https://img.shields.io/badge/IJCAI-2024-limegreen)](https://arxiv.org/abs/2407.04363) [![Code](https://img.shields.io/badge/Code-GitHub-cornflowerblue)](https://github.com/AIRI-Institute/AriGraph)

* **Agents of Change: Self-Evolving LLM Agents for Strategic Planning**
* **Know Where You’re Uncertain When Planning with Multimodal Foundation Models: A Formal Framework**
* **Large language models for planning: A comprehensive and systematic survey**
* **BeamAggR: Beam Aggregation Reasoning over Multi-source Knowledge for Multi-hop Question Answering**
* **Rag-kg-il: A multi-agent hybrid framework for reducing hallucinations and enhancing llm reasoning through rag and incremental knowledge graph learning integration**
* **Large language models as commonsense knowledge for large-scale task planning**
* **Knowagent: Knowledge-augmented planning for llm-based agents**
* **Text-image alignment for diffusion-based perception** [![CVPR]()]()
* **Vision-language model-based physical reasoning for robot liquid perception** [![IROS]()]()
* **VECSR: Virtually Embodied Common Sense Reasoning System**
* **Web agents with world models: Learning and leveraging environment dynamics in web navigation**
* **RbFT: Robust Fine-tuning for Retrieval-Augmented Generation against Retrieval Defects**
* **Large language models as commonsense knowledge for large-scale task planning** [![NeurIPS]()]()
* **Focus on your question! interpreting and mitigating toxic cot problems in commonsense reasoning**
* **Knowledge Verification to Nip Hallucination in the Bud** [![EMNLP]()]()
* **Neural-symbolic methods for knowledge graph reasoning: A survey** [![ACM]()]()
* **Contrastive chain-of-thought prompting**
* **Can llm be a good path planner based on prompt engineering? mitigating the hallucination for path planning**
* **Insight-v: Exploring long-chain visual reasoning with multimodal large language models**
* **Do i know this entity? knowledge awareness and hallucinations in language models**
* **KnowMap: Efficient Knowledge-Driven Task Adaptation for LLMs**
* **Robotouille: An Asynchronous Planning Benchmark for LLM Agents**
* **Review of Case-Based Reasoning for LLM Agents: Theoretical Foundations, Architectural Components, and Cognitive Integration**
* **Uncertainty of thoughts: Uncertainty-aware planning enhances information seeking in large language models**
* **Language models, agent models, and world models: The law for machine reasoning and planning**
* **Towards reasoning in large language models: A survey**
* **Agent Capability Negotiation and Binding Protocol (ACNBP)**
* **Enhance Mobile Agents Thinking Process Via Iterative Preference Learning**
* **TARGA: Targeted Synthetic Data Generation for Practical Reasoning over Structured Data**
* **Attentive Reasoning Queries: A Systematic Method for Optimizing Instruction-Following in Large Language Models**
* **Lisa: Reasoning segmentation via large language model**
* **Focus on your question! interpreting and mitigating toxic cot problems in commonsense reasoning**
* **WorldEval: World Model as Real-World Robot Policies Evaluator**
* **Introspective Planning: Aligning Robots’ Uncertainty with Inherent Task Ambiguity**



## :star2:2 Execution Hallucinations
* **Granite-Function Calling Model: Introducing Function Calling Abilities via Multi-task Learning of Granular Tasks** [![ACL](https://img.shields.io/badge/ACL-2024-limegreen)](https://aclanthology.org/2024.emnlp-industry.85/) [![models](https://img.shields.io/badge/Models-huggingface-9F88FF)](https://huggingface.co/ibm-granite/granite-20b-functioncalling)
* **APILOT: Navigating Large Language Models to Generate Secure Code by Sidestepping Outdated API Pitfalls** [![CoRR](https://img.shields.io/badge/CoRR-2024-limegreen)](https://arxiv.org/pdf/2409.16526)
* **Toolace: Winning the points of llm function calling** [![arxiv](https://img.shields.io/badge/arxiv-2024.09-limegreen)](https://arxiv.org/abs/2409.00920) [![models](https://img.shields.io/badge/Models-huggingface-9F88FF)](https://huggingface.co/Team-ACE) [![datasets](https://img.shields.io/badge/Datasets-huggingface-00DDAA)](https://huggingface.co/Team-ACE)
* **ALGO: Synthesizing Algorithmic Programs with Generated Oracle Verifiers** [![NeurIPS](https://img.shields.io/badge/NeurlPS-2023-limegreen)](https://arxiv.org/abs/2305.14591) [![Code](https://img.shields.io/badge/Code-GitHub-cornflowerblue)](https://github.com/zkx06111/ALGO)
* 
* **ACEBench: Who Wins the Match Point in Tool Learning?**
* **ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs**
* **Learning Evolving Tools for Large Language Models**
* **Tool Unlearning for Tool-Augmented LLMs**
* **Enhancing Tool Learning in Large Language Models with Hierarchical Error Checklists**
* **ToolRegistry: A Protocol-Agnostic Tool Management Library for Function-Calling LLMs**
* **Retool: Reinforcement learning for strategic tool use in llms**
* **Geckopt: Llm system efficiency via intent-based tool selection**
* **Rag-mcp: Mitigating prompt bloat in llm tool selection via retrieval-augmented generation**
* **Confucius: Iterative Tool Learning from Introspection Feedback by Easy-to-Difficult Curriculum**
* **CRITIC: Large Language Models Can Self-Correct with Tool-Interactive Critiquing**
* **RepoAudit: An Autonomous LLM-Agent for Repository-Level Code Auditing**
* **NesTools: A Dataset for Evaluating Nested Tool Learning Abilities of Large Language Models**
* **GenTool: Enhancing Tool Generalization in Language Models through Zero-to-One and Weak-to-Strong Simulation**
* **Tool Documentation Enables Zero-Shot Tool-Usage with Large Language Models**
* **An llm compiler for parallel function calling**

## :star2:3 Perception Hallucinations
* **Comparative Analysis of AI Agent Architectures for Entity Relationship Classification**
* **Ferret: Refer and ground anything anywhere at any granularity**
* **Florence-VL: Enhancing Vision-Language Models with Generative Vision Encoder and Depth-Breadth Fusion**
* **Re-Aligning Language to Visual Objects with an Agentic Workflow**
* **Mitigating hallucination in visual language models with visual supervision**
* **Multi-news+: Cost-efficient dataset cleansing via llm-based data annotation**
* **Editing Factual Knowledge in Language Models**
* **Seeing is believing: Mitigating hallucination in large vision-language models via clip-guided decoding**
* **EMMA: Efficient Visual Alignment in Multi-Modal LLMs**
* **Asynchronous LLM Function Calling**
* **HallusionBench: An Advanced Diagnostic Suite for Entangled Language Hallucination and Visual Illusion in Large Vision-Language Models**
* **Detecting and preventing hallucinations in large vision language models**
* **ContextualLVLM-Agent: A Holistic Framework for Multi-Turn Visually-Grounded Dialogue and Complex Instruction Following**
* **G-retriever: Retrieval-augmented generation for textual graph understanding and question answering**
* **Causal-LLaVA: Causal Disentanglement for Mitigating Hallucination in Multimodal Large Language Models**
* **Vcoder: Versatile vision encoders for multimodal large language models**
* **Hydra: An Agentic Reasoning Approach for Enhancing Adversarial Robustness and Mitigating Hallucinations in Vision-Language Models**
* **Text-image alignment for diffusion-based perception**
* **Vision-language model-based physical reasoning for robot liquid perception**
* **Large language model agent for fake news detection**

## :star2:4 Memorization Hallucinations
* **Knowledge unlearning for llms: Tasks, methods, and challenges** [![CoRR](https://img.shields.io/badge/CoRR-2023-limegreen)](https://openreview.net/forum?id=PvwM8Ehrmm)
* 
* **MIRIX: Multi-Agent Memory System for LLM-Based Agents**
* **What You Want to Forget: Efficient Unlearning for LLMs**
* **Improving factuality with explicit working memory**
* **Compress to Impress: Unleashing the Potential of Compressive Memory in Real-World Long-Term Conversations**
* **Flashattention: Fast and memory-efficient exact attention with io-awareness**
* **Who’s harry potter? approximate unlearning for LLMs**
* **Alphaedit: Null-space constrained model editing for language models**
* **Does fine-tuning LLMs on new knowledge encourage hallucinations?**
* **Model Editing Harms General Abilities of Large Language Models: Regularization to the Rescue**
* **Evaluating Memory in LLM Agents via Incremental Multi-Turn Interactions**
* **Memory sandbox: Transparent and interactive memory management for conversational agents**
* **Editing models with task arithmetic**
* **AIstorian lets AI be a historian: A KG-powered multi-agent system for accurate biography generation**
* **PMET: Precise Model Editing in a Transformer**
* **Refine Knowledge of Large Language Models via Adaptive Contrastive Learning**
* **Memos:A memory os for ai system**
* **Unveiling the pitfalls of knowledge editing for large language models**


## :star2:5 Communication Hallucinations
* **Autonomous Agents for Collaborative Task under Information Asymmetry** [![NeurIPS](https://img.shields.io/badge/NeurlPS-2024-limegreen)](https://openreview.net/forum?id=mp6OWpDIJC) [![Code](https://img.shields.io/badge/Code-GitHub-cornflowerblue)](https://github.com/thinkwee/iAgents)
* **LLMs Working in Harmony: A Survey on the Technological Aspects of Building Effective LLM-Based Multi Agent Systems** [![arxiv](https://img.shields.io/badge/arxiv-2025.04-limegreen)](https://arxiv.org/abs/2504.01963)
* **Cautiously-optimistic knowledge sharing for cooperative multi-agent reinforcement learning** [![AAAI](https://img.shields.io/badge/AAAI-2024-limegreen)](https://arxiv.org/pdf/2312.12095)
* **Challenges in Human-Agent Communication** [![arxiv](https://img.shields.io/badge/arxiv-2024.12-limegreen)](https://arxiv.org/abs/2412.10380)
* 
* **Preventing Rogue Agents Improves Multi-Agent Collaboration**
* **Why Do Multi-Agent LLM Systems Fail?**
* **Learning to Clarify: Multi-turn Conversations with Action-Based Contrastive Self-Training**
* **MultiAgentBench: Evaluating the Collaboration and Competition of LLM agents**
* **AgentDropout: Dynamic Agent Elimination for Token-Efficient and High-Performance LLM-Based Multi-Agent Collaboration**
* **Chateval: Towards better llm-based evaluators through multi-agent debate**
* **AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors**
* **Internet of agents: Weaving a web of heterogeneous agents for collaborative intelligence**
* **Optima: Optimizing effectiveness and efficiency for llm-based multi-agent system**
* **Goal Awareness for Conversational AI: Proactivity, Non-collaborativity, and Beyond**
* **Enhancing Multi-Agent Consensus through Third-Party LLM Integration: Analyzing Uncertainty and Mitigating Hallucinations in Large Language Models**
* **A survey of agent interoperability protocols: Model Context Protocol(MCP), Agent Communication Protocol (ACP), Agent-to-Agent Protocol (A2A), and Agent Network Protocol (ANP)**
* **Heterogeneous Swarms: Jointly Optimizing Model Roles and Weights for Multi-LLM Systems**
* **Embodied llm agents learn to cooperate in organized teams**
* **MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework**
* **CP-AgentNet: Autonomous and Explainable Communication Protocol Design Using Generative Agents**
* **Camel: Communicative agents for" mind" exploration of large language model society**
* **Theory of mind for multi-agent collaboration via large language models**
* **Encouraging divergentthinking in large language models through multi-agent debate**

## :star2:Mitigating Hallucination
* **Calibrating Verbal Uncertainty as a Linear Feature to Reduce Hallucinations**
* **Towards Mitigating LLM Hallucination via Self Reflection**
* **Hallucination augmented contrastive learning for multimodal large language model**
* **Tug-of-war between knowledge: Exploring and resolving knowledge conflicts in retrieval-augmented language models**
* **Cutting off the head ends the conflict: A mechanism for interpreting and mitigating knowledge conflicts in language models**
* **Simulation Agent: A Framework for Integrating Simulation and Large Language Models for Enhanced Decision-Making**
* **Contrastive representation learning: A framework and review**
* **Volcano: Mitigating Multimodal Hallucination through Self-Feedback Guided Revision**
* **Mitigating object hallucinations in large vision-language models through visual contrastive decoding**
* **Banishing LLM hallucinations requires rethinking generalization**
* **Treble counterfactual vlms: A causal approach to hallucination**
* **When hindsight is not 20/20: Testing limits on reflective thinking in large language models**
* **Contrastive modality-disentangled learning for multimodal recommendation**
* **Generative Causality-driven Network for Graph Multi-task Learning**

## :star2:Detecting Hallucination
* **Lettucedetect: A hallucination detection framework for rag applications**
